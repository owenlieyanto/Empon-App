{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Split Image Folder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_kUnWixpDet",
        "outputId": "e290a23d-170d-48d6-876e-3306e4e0dd99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/')\n",
        "os.getcwd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cdpyC1GmonPJ",
        "outputId": "48112583-a7a8-47db-c3dd-14578825ed2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POIt-ccfc4ud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91a3172-63cb-4a81-b6c9-dd7c8ca1969c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/empon_data_set/lengkuas\n",
            "Total images  : lengkuas 128\n",
            "Training : lengkuas 96\n",
            "Validation : lengkuas 25\n",
            "Testing : lengkuas 7\n",
            "/content/drive/MyDrive/empon_data_set/temulawak\n",
            "Total images  : temulawak 128\n",
            "Training : temulawak 96\n",
            "Validation : temulawak 25\n",
            "Testing : temulawak 7\n",
            "/content/drive/MyDrive/empon_data_set/kencur\n",
            "Total images  : kencur 128\n",
            "Training : kencur 96\n",
            "Validation : kencur 25\n",
            "Testing : kencur 7\n",
            "/content/drive/MyDrive/empon_data_set/kunyit_merah\n",
            "Total images  : kunyit_merah 126\n",
            "Training : kunyit_merah 94\n",
            "Validation : kunyit_merah 25\n",
            "Testing : kunyit_merah 7\n",
            "/content/drive/MyDrive/empon_data_set/kunyit_putih\n",
            "Total images  : kunyit_putih 124\n",
            "Training : kunyit_putih 93\n",
            "Validation : kunyit_putih 24\n",
            "Testing : kunyit_putih 7\n",
            "/content/drive/MyDrive/empon_data_set/jahe_putih\n",
            "Total images  : jahe_putih 122\n",
            "Training : jahe_putih 91\n",
            "Validation : jahe_putih 24\n",
            "Testing : jahe_putih 7\n",
            "/content/drive/MyDrive/empon_data_set/kunyit_hitam\n",
            "Total images  : kunyit_hitam 127\n",
            "Training : kunyit_hitam 95\n",
            "Validation : kunyit_hitam 25\n",
            "Testing : kunyit_hitam 7\n",
            "/content/drive/MyDrive/empon_data_set/kunyit_kuning\n",
            "Total images  : kunyit_kuning 132\n",
            "Training : kunyit_kuning 99\n",
            "Validation : kunyit_kuning 26\n",
            "Testing : kunyit_kuning 7\n",
            "/content/drive/MyDrive/empon_data_set/jahe_merah\n",
            "Total images  : jahe_merah 129\n",
            "Training : jahe_merah 96\n",
            "Validation : jahe_merah 26\n",
            "Testing : jahe_merah 7\n",
            "/content/drive/MyDrive/empon_data_set/jahe_emprit\n",
            "Total images  : jahe_emprit 116\n",
            "Training : jahe_emprit 87\n",
            "Validation : jahe_emprit 23\n",
            "Testing : jahe_emprit 6\n"
          ]
        }
      ],
      "source": [
        "# source:\n",
        "# https://stackoverflow.com/questions/53074712/how-to-split-folder-of-images-into-test-training-validation-sets-with-stratified\n",
        "\n",
        "## I made this for TB vs Normal image datasets by improving above code\n",
        "## import libraries\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# creating train / val /test\n",
        "root_dir = '/content/drive/MyDrive/empon_data_set/'\n",
        "new_root = 'empon_data_set_splitted/'\n",
        "classes = [\n",
        "          'lengkuas',\n",
        "          'temulawak',\n",
        "          'kencur',\n",
        "          'kunyit_merah',\n",
        "          'kunyit_putih',\n",
        "          'jahe_putih',\n",
        "          'kunyit_hitam',\n",
        "          'kunyit_kuning',\n",
        "          'jahe_merah',\n",
        "          'jahe_emprit'\n",
        "          ]\n",
        "\n",
        "for cls in classes:\n",
        "    os.makedirs(root_dir + new_root+ 'train/' + cls)\n",
        "    os.makedirs(root_dir +new_root +'val/' + cls)\n",
        "    os.makedirs(root_dir +new_root + 'test/' + cls)\n",
        "    \n",
        "## creating partition of the data after shuffeling\n",
        "\n",
        "for cls in classes:\n",
        "    src = root_dir + cls # folder to copy images from\n",
        "    print(src)\n",
        "\n",
        "    allFileNames = os.listdir(src)\n",
        "    np.random.shuffle(allFileNames)\n",
        "\n",
        "    ## here 0.75 = training ratio , (0.95-0.75) = validation ratio , (1-0.95) =  \n",
        "    ##training ratio  \n",
        "    train_FileNames,val_FileNames,test_FileNames = np.split(np.array(allFileNames),[int(len(allFileNames)*0.75),int(len(allFileNames)*0.95)])\n",
        "\n",
        "    # #Converting file names from array to list\n",
        "\n",
        "    train_FileNames = [src+'/'+ name for name in train_FileNames]\n",
        "    val_FileNames = [src+'/' + name for name in val_FileNames]\n",
        "    test_FileNames = [src+'/' + name for name in test_FileNames]\n",
        "\n",
        "    print('Total images  : '+ cls + ' ' +str(len(allFileNames)))\n",
        "    print('Training : '+ cls + ' '+str(len(train_FileNames)))\n",
        "    print('Validation : '+ cls + ' ' +str(len(val_FileNames)))\n",
        "    print('Testing : '+ cls + ' '+str(len(test_FileNames)))\n",
        "    \n",
        "    ## Copy pasting images to target directory\n",
        "\n",
        "    for name in train_FileNames:\n",
        "        shutil.copy(name, root_dir + new_root+'train/'+cls )\n",
        "\n",
        "\n",
        "    for name in val_FileNames:\n",
        "        shutil.copy(name, root_dir +new_root+'val/'+cls )\n",
        "\n",
        "\n",
        "    for name in test_FileNames:\n",
        "        shutil.copy(name,root_dir + new_root+'test/'+cls )\n",
        "\n"
      ]
    }
  ]
}